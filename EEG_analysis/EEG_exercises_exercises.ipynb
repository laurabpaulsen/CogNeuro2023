{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of EEG data\n",
    "\n",
    "In this notebook, we will go through the basics of preprocessing EEG data using MNE. We will be using the MNE sample data, so remember to run `pip install mne[data]` from the terminal.\n",
    "\n",
    "To preprocces the data following steps are performed\n",
    "1. Load the data\n",
    "2. Exclude bad channels\n",
    "3. Common average reference\n",
    "4. Filtering\n",
    "5. Artefact rejection\n",
    "\n",
    "After preprocessing the data is epoched for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the sample data\n",
    "\n",
    "Information about the sample data can be found [here](https://mne.tools/stable/overview/datasets_index.html). Have a quick read-through to understand the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file & loading in the data\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n",
    "                                    'sample_audvis_raw.fif')\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file) # raw is an MNE object that contains the data of the class Raw\n",
    "raw.info['bads'] = []\n",
    "\n",
    "raw.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "Looking at the ouput from the load_data() function, answer the following questions:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many EEG channels are there?\n",
    "2. Do you see any EEG channels marked as bad during recording?\n",
    "3. What is the sampling frequency?\n",
    "4. How many minutes of data were recorded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only EEG and stimulus data & plotting raw data\n",
    "raw.pick_types(meg=False, eeg=True, stim=True, exclude=[])\n",
    "raw.plot(); # the ; at the end of the line suppresses the output (if not used, the plot will be displayed twice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we are plotting using the default argument values of the plot() function. Try to play around with `Raw.plot()` method in order to:\n",
    "\n",
    "**1. Plot all EEG channels simultaneously**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot a full minute of the recording**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exclude bad channels\n",
    "When plotting all channels simultaneously, it is evident that one of the channels is not really picking up any signal (that is, it is flat). This is a bad channel and should be excluded from further analysis. There are other ways that channels might be bad, such as being too noisy, or picking up signals from other parts of the body. In this case, we will just exclude the channel that is flat.\n",
    "\n",
    "**Begin by marking the channel as bad using the info attribute of the raw object. Then, plot the data again to see that the channel is now excluded.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After marking the channel as bad, excluded it by using the pick_types() function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Common average reference\n",
    "The idea behind average reference is to compute the average of the signal at all EEG electrodes and subtract it from the EEG signal at every electrode for every time point. To set this “virtual reference” that is the average of all channels, you can use set_eeg_reference() with ref_channels='average'. This is done after excluding bad channels, so the average is computed only over the good channels.\n",
    "\n",
    "The rationale behind this is that the average of all the potentials recorded on the whole head due to current sources inside it is zero, this would make for a quiet or electrically neutral reference. However, in practice, to achieve such an ideal reference one would require large number of electrodes that cover the whole head uniformly, which is not the case in EEG recordings where limited number of electrodes cover mostly the upper part of the head.\n",
    "\n",
    "If you want to know more, this is a good [resource](https://pressrelease.brainproducts.com/referencing/#20)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the reference for the EEG data as average reference** \n",
    "\n",
    "*Hint: See this [link](https://mne.tools/stable/auto_tutorials/preprocessing/55_setting_eeg_reference.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the data after using the average as a reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering\n",
    "Now let's filter the data. **Apply a high-pass filter at 0.1 Hz and a low-pass filter at 40 Hz, following the typical practises of EEG preprocessing.** The high-pass filter minimises slow drifts in the data (e.g. scalp potentials), while the low-pass filter excludes high-frequency noise (e.g. line noise (50 Hz) or EMG (muscle-related artefacts), with frequencies higher than the frequencies of the signal we are interested in.\n",
    "\n",
    "*Hint: The `Raw` class has a `filter()` method that can be used to filter the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the data to inspect the effect of the filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "1. Compare to the unfiltered data. What is the effect of the filtering on the data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Artefact rejection\n",
    "There are many ways to detect and deal with artefacts. Today, we simply select a value and reject anything above or below that value. We do this because we determine that values over or under this threshold are liekly not related to brain activity. For now, we just specify the treshhold and then we use it to remove artefacts while epoching further along.\n",
    "\n",
    "There are better ways to reject artefacts, such as using the ICA algorithm. An optional exercise using ICA will be provided at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejecting everything over or under a threshold of 150 microvolts\n",
    "# anything above or belove this threshold is likely not brain activity but artefacts\n",
    "# this is not doing anything yet, we just specify the threshold for later!\n",
    "\n",
    "# extra note: using a dictionary as it allows to specify different thresholds for different channels, for example if both EEG and MEG is recorded (however we only have one channel type here)\n",
    "reject = {'eeg': 150e-6}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoching of EEG data\n",
    "Now that the data has been preprocessed, we can epoch the data. Epoching is the process of cutting the continuous data into smaller segments, called epochs. Each epoch is a time window of the data, centered around an event of interest.\n",
    "\n",
    "In MNE toolkit, the `Epochs` class is used to represent data that has been segmented into epochs, and it provides methods for averaging, baseline correction, plotting, and so forth.\n",
    "\n",
    "For a great overall introduction see MNE's [epoch overview](https://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html).\n",
    "\n",
    "**To begin with we need to locate the events. This can be done using the find_events() function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary of what each event ID represents.**\n",
    "\n",
    "By using '/' we can actually later index one dimension *across* the other, i.e. if we just write 'left' we get all events presented to the left side, both auditory and visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise the events by using the mne.viz.plot_events() function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Establish a time window for the epochs.**\n",
    "\n",
    "One suggestion is to use a time window of 200 ms before the stimulus onset to 500 ms after the stimulus onset. \n",
    "The 200 milliseconds before the onset of the stimulus enables us to examine a baseline of activity without stimulus presentation. The 500 milliseconds after the stimulus onset denote the time in which we expect the effect to occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.2, 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a `picks` variable with only EEG channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the epochs by using the mne.Epochs class**\n",
    "* Use the `reject` argument to reject epochs that are above or below the threshold we set earlier\n",
    "* Use the `tmin` and `tmax` arguments to set the time window for the epochs\n",
    "* Use the `baseline` argument to set the baseline for the epochs (from -0.2 seconds to 0 seconds relative to the event onset) \n",
    "\n",
    "*Hint: See this [link](https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs) on the `Epochs` class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample the data\n",
    "To reduce the amount of data we have to work with as well as the amount of time it takes to run the analysis the data is downsampled. This is done after epoching, since before epoching can potentially mess with the precision of the extraction of epochs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resample the data to 250 Hz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERP analysis\n",
    "Now that the data is epoched and resampled, we can start to analyse the data. \n",
    "\n",
    "**Group the epochs by modality (i.e. visual and auditory)**\n",
    "\n",
    "*Hint: See this [link](https://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html#subselecting-epochs) on how to subselect epochs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now use the plot_image() method of the Epochs class to plot the channel 'EEG 021' for both auditory and visual epochs**\n",
    "\n",
    "These plots show each epoch as one row of the image map for the chosen channel, with color representing signal magnitude. The average evoked response and the sensor location are shown below the image. This gives us an idea of whether there is consistency in the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. In your view, which is the most consistent signal of the two? Why do you think that is? (*hints: where is the EEG 021 channel located on the scalp? Try using plot_sensors and flagging show_names=True*)\n",
    "\n",
    "2. Which channel would you choose if you were to reverse the pattern of the signal consistencies? Why? **Try it out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evoked responses\n",
    "Unlike `Epochs`, which contain multiple trials that are each associated with a condition label (that is the event ID), `Evoked` objects are averages across trials for a single condition. Thus we have to create a separate `Evoked` object for each condition in our experiment.\n",
    "\n",
    "**Create an Evoked object for each modality**\n",
    "\n",
    "*Hint: use the average() method of the Epochs class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the two evokeds**\n",
    "\n",
    "*Hint: use mne.viz.plot_compare_evokeds()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a closer look at these averaged responses, here visualised with the global field power (GFP). GFP is actually the same as taking the standard deviation across all channels in each time sample. This tells us in which timepoints we see the biggest difference between different channels, which in turn is indicative of some kind of (more or less) focal activity. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. Looking at the plot, where in time do is the standard deviation across all channels the highest for visual and auditory, respectively?\n",
    "2. Do those timepoints match any well-known components relevant in this context? (*hint: N100 and N170*)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets use the plot_joint() method of the Evoked class to plot the evoked responses for both modalities.**\n",
    "\n",
    "This function generates a combination of “butterfly” plots (waveforms of all electrodes overlaid) and topographic maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "1. Do those plots match your observations from the GFP-plots?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional exercise: Independent Component Analysis (ICA)\n",
    "ICA can be used for artefact detection, since it identifies seperate components of the signal that have been combined during recording. That means that we can actually separate noise compoenents, such as eye blinks, from the rest of the signal, and thereby exclude them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn # scikit-learn is needed to run ICA (Independent Component Analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some quick preprocessing code of the raw data to get you started. Just run the chunk below and read the comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file & loading in the data\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n",
    "                                    'sample_audvis_raw.fif')\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file) # raw is an MNE object that contains the data of the class Raw\n",
    "raw.info['bads'] = []\n",
    "raw.load_data()\n",
    "\n",
    "# pick only EEG\n",
    "raw.pick_types(meg=False, eeg=True, stim=True, exclude=[])\n",
    "\n",
    "# bad channels\n",
    "raw.info['bads'] = ['EEG 053']\n",
    "\n",
    "# common average\n",
    "raw.set_eeg_reference(ref_channels='average', ch_type='eeg')\n",
    "\n",
    "\n",
    "# high-pass \n",
    "# ICA is sensitive to slow drifts, therefore we are here using a high high-pass filter! \n",
    "# Note however, that when applying the ICA, we will do it to data high-pass filtered at 0.1 Hz\n",
    "# See https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA\n",
    "raw_fit = raw.copy().filter(1, None)\n",
    "\n",
    "# low-pass \n",
    "raw_fit = raw_fit.filter(None, 40)\n",
    "\n",
    "# high and low-pass filtering for the data not used to fit the ICA\n",
    "raw = raw.filter(0.1, None)\n",
    "\n",
    "# low-pass \n",
    "raw = raw.filter(None, 40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up and fit ICA with mne.preprocessing.ICA() with 800 iterations with a random seed at 7 (for reproducibility) and n_components=0.95**\n",
    "\n",
    "n_components=0.95 ensures that the number of components selected explain at least 95% of the variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the ICA components**\n",
    "\n",
    "*Hint: ica.plot_components*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the time courses of the ICA components**\n",
    "\n",
    "*Hint: ica.plot_sources*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. Which components do you suspect to be noise? (*hint: look at the topographies of the components and the time courses of the components*)\n",
    "\n",
    "**When you have identified them, show them to Laura!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclude the eye components and apply ica to the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the data after filtering and using ICA to reject artefacts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now like above epoch the data and downsample it. Then make the single-trial and evoked plots.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "1. Compare your results with and without ICA - can you tell any differences between the two, just qualitatively speaking?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
